# Influence of the sample size on the Shapiro-Wilk, Kolmogorov-Smirnov and Anderson-Darling normality tests.

Simulation is defined as the computational representation of a real model. To develop a computational model of processes, it is necessary to have both advanced knowledge about the process to be modeled and statistics. Computational modeling of a real-world system means creating a digital replica of this system that is capable of behaving similarly to the original system so that, when interacting with the user, it allows experimentation with the ultimate intention of better understanding the real system through statistical inference. For a model to create an artificial history of the real system, it is essential that it brings with it the possibility of exhibiting behavior that varies over time, similar to the real system itself. In simulation-oriented models, this goal is achieved by using probability distributions to represent the multiplicity of occurrences of random events, but there are three methods to determine which probability distribution best fits a specific data set: graphical methods (histograms, boxplots, Q-Q plots), numerical methods (skewness and kurtosis coefficients), and formal tests. The goodness-of-fit of a data set describes how well the observed data set fits another reference data set. This study compares the influence of data set size on the Shapiro-Wilk (SW), Kolmogorov-Smirnov (KS), and Anderson-Darling (AD) goodness-of-fit tests. The study results were obtained after repeated executions of the goodness-of-fit test on different normal data sets with variations in the sample space size.

You can see the results of the study in the full article in the Docs folder.